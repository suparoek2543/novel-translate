from google import genai
from google.genai import types
import cloudscraper
import requests
from bs4 import BeautifulSoup
import time
import os
import re
import random
import json
from urllib.parse import urljoin

# ==========================================
# ‚öôÔ∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
# ==========================================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") 
NOVEL_MAIN_URL = "https://kakuyomu.jp/works/822139841708705081"

JSON_DB_FILE = "novels.json"
HISTORY_FILE = "history_novel_2.txt"

if GEMINI_API_KEY:
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
    except:
        client = None
else:
    client = None

scraper = cloudscraper.create_scraper(
    browser={'browser': 'chrome', 'platform': 'windows', 'desktop': True}
)

# ==========================================
# üõ†Ô∏è ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ JSON ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á)
# ==========================================

def get_novel_title():
    """‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å"""
    print(f"üìñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å: {NOVEL_MAIN_URL}")
    try:
        response = scraper.get(NOVEL_MAIN_URL)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á (Kakuyomu ‡πÉ‡∏ä‡πâ id="workTitle")
        title_elem = soup.select_one('#workTitle')
        if not title_elem:
             # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏•‡∏≠‡∏á‡∏´‡∏≤ h1
             title_elem = soup.select_one('h1')
             
        title = title_elem.text.strip() if title_elem else "‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏ä‡∏∑‡πà‡∏≠"
        print(f"‚úÖ ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á: {title}")
        return title
    except Exception as e:
        print(f"‚ùå ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
        return "‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏ä‡∏∑‡πà‡∏≠"

def save_to_json(novel_title, ep_data):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á JSON ‡πÅ‡∏ö‡∏ö‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà"""
    data = {}
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
    if os.path.exists(JSON_DB_FILE):
        with open(JSON_DB_FILE, "r", encoding="utf-8") as f:
            try:
                content = f.read()
                if content: data = json.loads(content)
                
                # ‚ö†Ô∏è ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Array [] ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤? (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Dict {})
                if isinstance(data, list):
                    print("‚ö†Ô∏è ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤ (Array) ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà...")
                    data = {} # ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏¥‡πâ‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô
            except:
                data = {}

    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ (‡πÉ‡∏ä‡πâ URL ‡πÄ‡∏õ‡πá‡∏ô ID ‡∏à‡∏∞‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥)
    novel_id = NOVEL_MAIN_URL
    
    # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ô Database ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
    if novel_id not in data:
        data[novel_id] = {
            "title": novel_title,
            "chapters": []
        }
    
    # 3. ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ï‡∏≠‡∏ô
    chapters = data[novel_id]["chapters"]
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏´‡∏°
    existing_idx = next((index for (index, d) in enumerate(chapters) if d["link"] == ep_data["link"]), None)
    
    if existing_idx is not None:
        chapters[existing_idx] = ep_data # ‡∏ó‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°
    else:
        chapters.append(ep_data) # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà
        
    data[novel_id]["chapters"] = chapters

    # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    with open(JSON_DB_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà {ep_data['ep_id']} ‡∏•‡∏á‡∏´‡∏°‡∏ß‡∏î '{novel_title}' ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢")

# ==========================================
# üõ†Ô∏è ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°
# ==========================================
# (‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÅ‡∏ï‡πà‡∏ï‡∏±‡∏î‡∏ï‡∏≠‡∏ô‡πÅ‡∏õ‡∏∞‡πÇ‡∏Ñ‡πâ‡∏î‡∏¢‡∏≤‡∏ß‡πÜ ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏π‡∏á‡πà‡∏≤‡∏¢)
# ... Load History, Get Url, Translate Smart ...
# (‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡∏à‡∏≤‡∏Å V.9 ‡∏ó‡∏µ‡πà‡∏ú‡∏°‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Main Loop ‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á)

def load_history():
    if not os.path.exists(HISTORY_FILE): return set()
    with open(HISTORY_FILE, "r", encoding="utf-8") as f: return set(l.strip() for l in f)

def save_to_history(url):
    with open(HISTORY_FILE, "a", encoding="utf-8") as f: f.write(url + "\n")

def get_first_episode_url():
    try:
        response = scraper.get(NOVEL_MAIN_URL)
        soup = BeautifulSoup(response.text, 'html.parser')
        l = soup.select_one('a#readFromFirstEpisode')
        if l: return urljoin(NOVEL_MAIN_URL, l['href'])
        # Fallback
        ts = re.compile(r'/works/\d+/episodes/\d+')
        ls = soup.find_all('a', href=ts)
        if ls: 
            sl = sorted(ls, key=lambda x: int(re.search(r'episodes/(\d+)', x['href']).group(1)))
            return urljoin(NOVEL_MAIN_URL, sl[0]['href'])
    except: pass
    return None

def find_next_link(soup, url):
    n = soup.select_one('a.widget-episode-navigation-next') or soup.select_one('a#contentMain-readNextEpisode') or soup.find('a', string=re.compile('Ê¨°„ÅÆ„Ç®„Éî„ÇΩ„Éº„Éâ'))
    return urljoin(url, n['href']) if n else None

def get_content_and_next_link(url, max=3):
    h={'Referer': NOVEL_MAIN_URL}
    for _ in range(max):
        try:
            time.sleep(1)
            r = scraper.get(url, headers=h, timeout=15)
            if r.status_code==200:
                s = BeautifulSoup(r.text, 'html.parser')
                t = s.select_one('.widget-episodeTitle').text.strip()
                b = s.select_one('.widget-episodeBody').get_text(separator="\n", strip=True)
                eid = re.search(r'episodes/(\d+)', url).group(1)
                return {"title":t, "content":b, "next_link":find_next_link(s, url), "ep_id":eid}
        except: time.sleep(2)
    return None

def translate_smart(text, r=0):
    if not client or not text: return None, "Error"
    ps = [
        f"‡πÅ‡∏õ‡∏•‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ó‡∏¢ ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏¢‡∏£‡∏∏‡πà‡∏ô:\n‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:\n{text[:15000]}",
        f"**‡πÅ‡∏õ‡∏•‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏•‡πà‡∏≠‡πÅ‡∏´‡∏•‡∏°**:\n‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:\n{text[:15000]}",
        f"‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á:\n‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:\n{text[:15000]}"
    ]
    try:
        res = client.models.generate_content(
            model='gemini-2.5-pro', contents=ps[min(r,2)],
            config=types.GenerateContentConfig(safety_settings=[
                types.SafetySetting(category='HARM_CATEGORY_HARASSMENT', threshold='BLOCK_NONE'),
                types.SafetySetting(category='HARM_CATEGORY_HATE_SPEECH', threshold='BLOCK_NONE'),
                types.SafetySetting(category='HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold='BLOCK_NONE'),
                types.SafetySetting(category='HARM_CATEGORY_DANGEROUS_CONTENT', threshold='BLOCK_NONE')
            ])
        )
        if not res.text: raise ValueError("Empty")
        return res.text, None
    except Exception as e:
        if r<2: time.sleep(2); return translate_smart(text, r+1)
        return None, str(e)

# ==========================================
# üöÄ Main Loop (‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÉ‡∏´‡∏°‡πà)
# ==========================================

def main():
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö Web Novel (Tree View Supported)...")
    
    # 1. ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏•‡∏¢ (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå)
    novel_title = get_novel_title()
    
    completed_urls = load_history()
    current_url = get_first_episode_url()
    
    if not current_url: 
        print("‚ùå ‡∏´‡∏≤‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠"); return

    ep_count = 1
    
    while current_url:
        print(f"\n[{ep_count}] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö: {current_url}")
        
        if current_url in completed_urls:
            print("   ‚è© ‡∏°‡∏µ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß -> ‡∏Ç‡πâ‡∏≤‡∏°")
            data = get_content_and_next_link(current_url) # ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ Next Link ‡πÄ‡∏â‡∏¢‡πÜ
            if data and data['next_link']:
                current_url = data['next_link']
                ep_count += 1
                continue
            else:
                break

        data = get_content_and_next_link(current_url)
        if not data: break

        title = data['title']
        translated, err = translate_smart(data['content'])
        
        if translated:
            print(f"   ‚úÖ ‡πÅ‡∏õ‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à -> ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á '{novel_title}'")
            
            ep_data = {
                "ep_id": data['ep_id'],
                "title": title,
                "content": translated,
                "link": current_url
            }
            
            # üü¢ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ save_to_json ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà (‡∏™‡πà‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢)
            save_to_json(novel_title, ep_data)
            
            save_to_history(current_url)
            completed_urls.add(current_url)
        else:
            print(f"   ‚ùå ‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô: {err}")

        if data['next_link']:
            print("   ‚û°Ô∏è ‡πÑ‡∏õ‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ...")
            current_url = data['next_link']
            ep_count += 1
            time.sleep(5)
        else:
            print("üèÅ ‡∏à‡∏ö‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á")
            break

if __name__ == "__main__":
    main()
